{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getting_started_with_deep_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumendra/cnn-visualisation/blob/master/notebooks/getting_started_with_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "b-rza-AISL33",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Started with Deep Learning (using Keras)"
      ]
    },
    {
      "metadata": {
        "id": "YpCvHdUzS3rf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST"
      ]
    },
    {
      "metadata": {
        "id": "yQjWtIB6Tdt3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Importing dependencies and setting seeds"
      ]
    },
    {
      "metadata": {
        "id": "EiLJfQ4dW-II",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **Importance of Seed**  \n",
        " Neural Network algorithms make heavy use of randomness, be it for initialization of layer weights or to decide which neurons to dropout.  \n",
        " As a result of this randomness, each training run of a neural network, is bound to produce slightly different results.  \n",
        " This can be a nuisance while experimenting. In order to ensure that our experiments are reproducible (getting the same output every time), by us or anyone else who chooses to run them, we need to seed this randomness.  \n",
        "\n",
        "---\n",
        "**Why are we setting two different seeds?**  \n",
        "Keras relies on `numpy` for some of it's randomness, so we need to seed numpy's random number generator.  \n",
        "Additionally, `Tensorflow` uses it's own random number generator, and since we are using Tensorflow, we need to seed it's random number generator as well.  \n",
        "\n",
        "---\n",
        "More info at -> https://machinelearningmastery.com/reproducible-results-neural-networks-keras/"
      ]
    },
    {
      "metadata": {
        "id": "ykL_rx5vTjXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f934548d-d551-4790-ed48-34ef736ae03c"
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FQqFtAaNTjuD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Declaring some constants"
      ]
    },
    {
      "metadata": {
        "id": "pZJ7QMPwa7-f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Epochs**  \n",
        "An `epoch` is said to have completed when our model trains over the entire train dataset `once`.  \n",
        "Hence, number of epochs simply defines the total number of passes our model will make on the entire dataset during training.  \n",
        "\n",
        "---\n",
        "**Batches**  \n",
        "Although the model needs to run over the entire dataset on every epoch, giving the entire dataset as input to the model at once is not feasible. Most of the times our datasets are huge, and using the entire dataset as input will consume a lot of memory.  \n",
        "Hence, we use the concept of batches.  \n",
        "i.e In a single epoch, we make multiple forward and backward passes on the neural network and each time give a subset of entire dataset as input. The size of this subset is called `batch_size`.  \n",
        "This consumes a lot less memory and also helps in training the network faster as we are now updating network weights after every `batch` rather than after every `epoch`.\n"
      ]
    },
    {
      "metadata": {
        "id": "OWO2KI75TuEw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uc-jLIc7T3Fd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Loading and making our dataset usable"
      ]
    },
    {
      "metadata": {
        "id": "3B-Zpf5IjCKn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Why Normalize?**  \n",
        "Normalization in case of image data means dividing it's pixel values by 255.  \n",
        "This brings all pixel values between (0,1).  \n",
        "We've observed that this makes training and convergence much more faster."
      ]
    },
    {
      "metadata": {
        "id": "GMPjfClbT1Em",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q1IY0ixArcxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "259fb460-f089-4387-e356-60487b4464f1"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_grid(arr):\n",
        "  f, axarr = plt.subplots(2,2)\n",
        "  axarr[0,0].imshow(arr[0])\n",
        "  axarr[0,1].imshow(arr[1])\n",
        "  axarr[1,0].imshow(arr[2])\n",
        "  axarr[1,1].imshow(arr[3])\n",
        "  \n",
        "  axarr[0,0].axis('off')\n",
        "  axarr[0,1].axis('off')\n",
        "  axarr[1,0].axis('off')\n",
        "  axarr[1,1].axis('off')\n",
        "\n",
        "plot_grid(x_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAFLCAYAAADiejquAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSKFwAEihcABIoXAASKFwAEihcABI8T/8iR3yij2gcAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DK2QQgNvrdGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b2525c9a-0aea-4216-9bf5-7f6114d4e239"
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train images')\n",
        "print(x_test.shape[0], 'test images')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train images\n",
            "10000 test images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o-b0g8hhUM99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. One hot encoding of output classes"
      ]
    },
    {
      "metadata": {
        "id": "c_nRENhyUFw0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to one hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0iQa24QwUmhr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Our first Model 😁"
      ]
    },
    {
      "metadata": {
        "id": "fe6FTGajWmH0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.1 Architecture"
      ]
    },
    {
      "metadata": {
        "id": "NvragukgVDMj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cfi_TOwQtCdP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ow6TUh4HWk_7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.2 Training (≖ ‿ ≖)"
      ]
    },
    {
      "metadata": {
        "id": "6get0qRfWgAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "fe1052e8-487c-42f9-9f31-c989c860379c"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.5004 - acc: 0.8416 - val_loss: 0.1263 - val_acc: 0.9637\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.1808 - acc: 0.9458 - val_loss: 0.0747 - val_acc: 0.9768\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.1266 - acc: 0.9616 - val_loss: 0.0571 - val_acc: 0.9820\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.1052 - acc: 0.9681 - val_loss: 0.0501 - val_acc: 0.9847\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.0881 - acc: 0.9730 - val_loss: 0.0461 - val_acc: 0.9851\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.0793 - acc: 0.9762 - val_loss: 0.0413 - val_acc: 0.9865\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.0712 - acc: 0.9789 - val_loss: 0.0388 - val_acc: 0.9871\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.0650 - acc: 0.9802 - val_loss: 0.0346 - val_acc: 0.9874\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.0581 - acc: 0.9819 - val_loss: 0.0372 - val_acc: 0.9885\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.0548 - acc: 0.9827 - val_loss: 0.0325 - val_acc: 0.9901\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.0515 - acc: 0.9836 - val_loss: 0.0322 - val_acc: 0.9901\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.0451 - acc: 0.9857 - val_loss: 0.0345 - val_acc: 0.9880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed39b055c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "YiPW-s4oWv4_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.3 Evaluation ᕦ⊙෴⊙ᕤ"
      ]
    },
    {
      "metadata": {
        "id": "uELdw91iXQGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c2eb246c-4192-41a1-ebc4-c225af00caae"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.034466968409749096\n",
            "Test accuracy: 0.988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BST6VVyZZQEb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Let's go Deeper! ᕕ( ᐛ )ᕗ"
      ]
    },
    {
      "metadata": {
        "id": "XKFsLNu5sl4b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Go Deeper](https://cdn-images-1.medium.com/max/1600/1*RuDCBpDFK4fuBo6W5OFsEw.jpeg)"
      ]
    },
    {
      "metadata": {
        "id": "W1qjlwc2Ztut",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.1 Architecture"
      ]
    },
    {
      "metadata": {
        "id": "wfLIhEPpZi1m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9BGWfXSItHxS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gri5Vw5gZwUA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.2 Training"
      ]
    },
    {
      "metadata": {
        "id": "eUg4ZzbmZyyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "f72bd0e5-c12f-41a6-a12f-75eafd621279"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.8186 - acc: 0.7277 - val_loss: 0.1234 - val_acc: 0.9634\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1952 - acc: 0.9457 - val_loss: 0.0789 - val_acc: 0.9767\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1336 - acc: 0.9648 - val_loss: 0.0605 - val_acc: 0.9827\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1093 - acc: 0.9711 - val_loss: 0.0537 - val_acc: 0.9845\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0907 - acc: 0.9764 - val_loss: 0.0485 - val_acc: 0.9859\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0824 - acc: 0.9779 - val_loss: 0.0476 - val_acc: 0.9872\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0708 - acc: 0.9819 - val_loss: 0.0387 - val_acc: 0.9889\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0635 - acc: 0.9829 - val_loss: 0.0389 - val_acc: 0.9891\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0581 - acc: 0.9848 - val_loss: 0.0424 - val_acc: 0.9884\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0541 - acc: 0.9860 - val_loss: 0.0437 - val_acc: 0.9874\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0481 - acc: 0.9876 - val_loss: 0.0406 - val_acc: 0.9903\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0446 - acc: 0.9875 - val_loss: 0.0385 - val_acc: 0.9917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed33e48a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "qBOz9dbBZ1Jy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.3 Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "WBlOWs9XZ350",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5c1574b8-e687-4ecf-95c5-a13c33cb2d9d"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.03849187142269034\n",
            "Test accuracy: 0.9917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n3oQdWiCbi6-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CIFAR10"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BcEtYgQ5uOz2"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Importing dependencies and setting seeds"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MPYQ7CAJuO0F",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "GENERATOR_SEED = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KXN3pkvyuO0S"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Declaring some constants"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7hvMYs1EuO0U",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "input_shape = (img_rows, img_cols, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tzYhRaNguO0Z"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Loading and making our dataset usable"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6Lp_Gns4uO0b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4567bf7c-c5d5-41ec-f319-363ad5e2a9cd",
        "id": "JOyehUQAuO0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_grid(arr):\n",
        "  f, axarr = plt.subplots(2,2)\n",
        "  axarr[0,0].imshow(arr[0])\n",
        "  axarr[0,1].imshow(arr[1])\n",
        "  axarr[1,0].imshow(arr[2])\n",
        "  axarr[1,1].imshow(arr[3])\n",
        "  \n",
        "  axarr[0,0].axis('off')\n",
        "  axarr[0,1].axis('off')\n",
        "  axarr[1,0].axis('off')\n",
        "  axarr[1,1].axis('off')\n",
        "\n",
        "plot_grid(x_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAFMCAYAAAD/fwoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztvdmTZdl13rfOdOcp56zMmqurCoUe\n0ACBJtAACYCQBFKCSMq0ZTvCofCD5QiHIvzgf8H/hCIsSxG2H2yHRcMQKIoCRGJiAwS72Y2eu6q6\n5qqcM2/e+Z7RD5Qc/tY62Q3Sxu5O8Pu9rZv37jPcs/fOu7/9reUVRVEIIYQQ8gvG/6hPgBBCyN8M\nOOEQQghxAiccQgghTuCEQwghxAmccAghhDiBEw4hhBAncMIhhBDiBE44hBBCnBC6OMiXvvwViPv9\nQ4irfm4+s1hBP+r5pQbEK4tNiJd7LdNGJYggDqt1fEOAl3941DdtxCmex0KvC7GfJRDP53PTxmw2\ng7hWr0GcSQbxZDoybXR7HXyhwM/E8xjiQPDaRUSCIIC43cJ71mziPY0iPE8Rkak6TuGp/1l8vKf6\nvERE0sKD+J/89//UvId8fPkfvvVdiB+9+wrEe3ffMZ/JMnwu1s5/AuLzV25AvLB+3rRRq2MbN996\nCeL7t1+HOBnafhSo8+gsYH8OazjOvPDFXzdtPHUNz312jOPZW2++CnGe2z4QJzgmvP3WGxAP+vsQ\nz2M7riQx9ufDgwnEowkeI81sGysrixAvLOKYkBVDbAOHOxERmU1xjPzm7/+RfdO/h79wCCGEOIET\nDiGEECdwwiGEEOIEJxrOW2+/BXF/H9cnF61UIN4SvrictfHv9VWIxzmuo4qIjDJcWyy8CsSTGa6t\nTqYl66QZ6kv7AeoPtRCPkaZWjwqUrlGtVtV5jLGNkjVfb7YEsY/Lt5Io7age2ps6UnrKYZZC3Gig\nhuP5VgfylC4mPv7PMpnhIm+a2EXfIKya18jpYXCEfW2phzpAsbJmPlOEqEGeOX8Z4izH58TPUY8Q\nEckn+LzOjg7wGFPULDaXcYwQETl/7imIzz11AeKNzbMQr67aa4kifH7THuo+586u499T259nsynE\n/SPUm/b38R6HlbJBEgeBhSU8r1oTj3E8ODJNVGs4NuUF3uNI9dXBcYnOPf/58z/zFw4hhBAncMIh\nhBDiBE44hBBCnOBEw6mHqHuIWsK/sGTXJy+u4f74VbVfvK71Bk8dQ0Smc1zTnSWocxTqM5W68umI\niCgfTpFjG91FXL9NE7ueWYmw3QwtNBJU8IbMYzxvEZEkxXNtqM+ETTxGrWJ1ktRDrcgvUG9KBY8R\n2FsqrSZe72iMa+2J2qjvl7QxHBzbF8npQely8RzjycRqFhevbUI8GuOzqH0pi8vY/0VEwgj/P756\n9RrEL37+sxBvrqEeIyLS7a5AnITYGRs11a9K5AkvRZ1jOkb9Za7uT6OOfUZEZKGH+tKVy5+E+J13\n3lMHtVrofI59r9tZgDhCyVqOBzumjULwu8pzvOCjI/yephOrc/9VSnjyFw4hhBAncMIhhBDiBE44\nhBBCnMAJhxBCiBOcbBqoeSiytdt42GubKHaJiCzV0dQU5Sgqjg5R7MpyO3dOlVHMVyJaRyX8DEuE\n9v4xJq8L1R1bbKMgOBygyCYiEitj51SZIwsl1rdUEk0RkSRGE5evkhBGykyaZVZkDNUugLkSeytK\nZfRzvH8iIvORMo8pc21VGVLT3Bphj8dWeCSnh1SZFr0UhfdqxW6+OVZm76V1FPTPP42GzNVzG6aN\nSKvgaoNKkuIY8e4WGkNFRCZ39vAzPo4j773xM4g/dwPFfBGRX3/hcxAXSjUfqE0xD+4/MW1UVGLc\nSgWNscsruMniwcNbtg2VaHQ0xXFmMMB7HkZ2B0+ng21Mp7gRQXnDS43t1WrFvHYS/IVDCCHECZxw\nCCGEOIETDiGEECc40XAWqniYutIbuk275rvSwSSRWY7rxMo7KUGoxAMRk1hyrhIEhkqQCQu7PpnN\ncb26CLDN3V1MZpcl+sxEhhNcF51kuG7cqqvianPbRiB4br6H68ZBFdeEp2NrHm1EeJxQrT3PVDLT\naWI1nFzwM/0RHqc/wXs8mtg2Zgn/zznNzCeoFbRUQcHOIporRUQ+86nnIT53+SrEQ2WmfO/OQ9PG\nQPWjUR/73kEfNZutbZussqOMn+Kjnvjt/+1fQhz9Q/usfvkLX8L3RPjMr68r/alALUVEpH+E2vBf\nvIrF40KVILTZVmOEiKRKP41HeD/UUGWKrYmIZGosOjjEc/UFNR49ZoqI9HrWpHsS7PmEEEKcwAmH\nEEKIEzjhEEIIcYITDWelh2u87Qj1llrN6i9+gOuTdZVYM1F7/3Oxe8yLAtcnY5WIM4tx7TUvrHel\nUGucRYh7zocxrmdnmb2WiSrilqp4OMbjPj60Xp7Ix890Rni9yTauvU6PbQGr88vK67CKXgivjf6B\n+ZH1MYxGeG7HQ9Rw9o9R87r30CbqzAInjx35BVGtor6aBFgccVpHf5uIyN0BPhev/einEB8eYALM\nx09soslI+ch0n5irQmdakxQRObOCz97u9n2IO8pTMuwPTBs3797FNs8s43lFeIwz57Agm4jIhnrt\nwTZqVu+9gfHqGauL3XugtKEE70ceY5yFVhvWSX6rIX630xl+ptOxWlL4VyioyF84hBBCnMAJhxBC\niBM44RBCCHGCk8X0jRXMDdap4J77VsPm4vGMnlKov6v126nVLHyl6yy1cb94s4na0uDY7pfvqjXL\nocqDdv8xfmY0txpORdl7NhvK/xMp3eMA99OLiMwLlVtO+XC6HVxHf/GTWIxKRGSwheuxxUS1sYzr\nt/OJfTxGI/wfpRrhZ86t43msrq6ZNnYG1iNETg+NBn6nu33sz7cfWg/N22+9CbGvdI5M5fWbDq2O\nGSjNZjpHfaU/xHioCqOJiNx79A7EzTo+r9evXMcPpFYH+tMffg/iC5cuQXztOhaGW1qyPpVqDa+/\n20EdxE9R+xzPy3JFoodo2kdvT5ZhP6vVsa+KiIwG+JmO8vtUlb4ex1bnnkzs2HsS/IVDCCHECZxw\nCCGEOIETDiGEECdwwiGEEOIEJ5sGFtto2gxjFMWrkT2NRhWTxs2nqtiSKg7W69kibrowUpzh/Jok\nKKo1Wtaw9mQPhbn376OYtzfE8yjJVSkXVDG53/01TGR49gwe9/945Y5p48e3tyFOcxQzQx+vddjH\nQlMiIpMRXku7rUTEDDdZ1GpWZKwoEbHh4XtSVbHpfEkhrfbh0LxGTg+9RTQ63n54E+Kte2iMFBFp\nRPjsHY8xseZosAuxV1K4rz/ETQD9KfbfUBlSl9dWTRt1tXFo8+KnID6nnu+7P/uxaSPwsO8lGW7G\n2dtHw/Szz94wbTx19TIeVxk7W5//NMSvv/vAtDGf4aaneaSMn4IbAPLCDk7b21gcrqITKy/oe2g3\nc0ynU/PaSfAXDiGEECdwwiGEEOIETjiEEEKc4ETDWV1cgnh6iGuvvldiMFSFvKYxrj+GHq61TkoK\nn+nZdJrg2mtvAdc4Y1XQSETkziNc4zwcKPOkSuYZ6KpHItKp4WdWQ9Qwaoe4vn21Y5P9bS1iuzt9\nXPOeT/DaXr2J6+oiIn6Ka7xJUyXi6yqTpm+/l24XtbV2roq4KWNYEdvkhxeVEZicLt5/HxNvvvv+\nbYifbL1vPpMpI2e7i8/A9asXIX7mxjOmja091Aru72GbK+v4/F64goZMEZH2EmoSO0fYRrGP+tOD\n+1Y72VOF3m58Ev/+t6+hZjMeWY1D1ZOUIsb++9ZPUDu6eh11XxGRtc0exD/56Q8g3t7BvpeUFFSc\nTfG4R6owXL2Fx8hLilSOJ1bXOQn+wiGEEOIETjiEEEKcwAmHEEKIE5xoOAvLuMd8oYW+HN+3fo/+\nAPfpJyoRn5/pAmx2bbFQ/p5WC/etJ4LxO3es7jGe4/pkrYb71GsVPEa9iRqHiMhCgGunr9zG4lJp\njG3Mu1bDWVnAc/XUHvskRV1sEtt147FK1hmneF6e0rhKatpJ5OOLha+SioZ4Lekc9SkRkaJEKyOn\nh5/84DsQh2uY8PLKjWfNZ+qqGNiNT16F+Po1LAaYzWwS3MLHZ3osmDg3jLCPBAHqDyIiSYr9dzw8\nhLirtOK05Fl9sItjU631GNvooCfw8pWLpo1C/a8/7WMCzHf/7DV8/9SOb898/TchfvY59PZMX0YN\n5/3b90wbjQZ6ALu9JfUOHGcHalwWEZnPmbyTEELIxwxOOIQQQpzACYcQQogTnGg4ojQaL7Kajaaq\n8ng1BPfth2qu9H07dyZK16nWMY/S/jbuOZ/s2/XJy4sqX5GqHVZTms31K5umDV99KA3w2vS6aBhg\nvjYRkXYFr39p4QrEV66eh/jugz83bbx7E9eaKyHqK0WBOlma2sfDV76jqILXkuc6n5MVgjyP/+ec\nZnYfonby6U/9PYirVdRsRUQWlSRzZgM1yENVPOzhbdRWRETiXBUp81BfCEJ89rLC6oeS6sJvqAsV\nGbbR6mLeOBGRgxHqur7qm3mhdZ8SzVJJMq0a3o+LG+cgrgW2DV+wvz77DPqOej3UsL41/bemje0t\nHHs2VzH3Yebh2BWV5L0cDKzX7iTY8wkhhDiBEw4hhBAncMIhhBDiBE44hBBCnOBk08B0hgkdvUSb\nEm1SufEYhag4wbkx9VHMH01sUa+Bem3zHF5ukeLfLyxbgfvKBorikxm+Z/MaFnCqFGpXgYgcHeP1\n17W56gAV1XPrZ0wb/TEKlZc/gca5zkJDxbbo09EeXu/RMW5OiJT46Rco0oqIJCrroK6TlakEgX6J\neVQXxiOni0ZrEeJIfZ19lVhWRKS6iAL2RCWSnaluU19o2zZy9TDNdCJd9efEGhJrdXyTr4qp5Sph\nbWvJFhCsFLihIaij0bOoYH/OPXseXqb6WoDHjZq4OafewlhEJJ1jfz54jIbypSZu3vidv/t108bL\nP7sH8Ugl85zNsZDjvKTYWq9tDbYnwV84hBBCnMAJhxBCiBM44RBCCHGCEw0nUwatIsN1/rI1/XoN\nE3y22qhRPFHFmO4+wrVGEZFQLS5XdrCY2mwHP3N11RpSv/YV1Eref4zrt+1NXCddXrKJN3f3cG21\n11Prtzket+LbxIW7e2jaDGt9iPf6WxA/3kJTmIhIFOE97HVwHX06xftVhPb/EU+JMrnSdHwP/+6V\nGHKZu/N0c+Y8Ggz1dzybWSPgzgCHmkoPDZVJihpFmTl8OsJnOinwuGGImmMaWA2y0UGD5eoS9qPi\nEMeVuKRomZfjcet1lYxYdd+8sG1kKvmwH+GHClXIcTS2GrWnBNSq+h4GatypN1B7ExH59S88B/F7\n79+H+M23t/E8BrbYWkUlTf0g+AuHEEKIEzjhEEIIcQInHEIIIU5wouH0eljkJw1xTXM0st6VIsE1\nzuMhekbuP8D1ydHIahb1Gs6nW3dxbXmthuvGm5sXTBu9DVyvjobKeKKSjJ791Aumjdo26i/1FLWj\nTPD6x2N7P840UCuKVZJBr4n3+GzT+gfaPdSXhge4Pru7cwBx4tl19FmsEiL6KMg0q7ieG09LtKTK\nhydvJR9fCg/1hkTpHJOh1RuqSucYDlALjWf4XE0Gto1I2XDaTdRoVhZQo+gsolYqIrLSw/PIQkzo\nO63itRxesP1onqFeKsrvk6XK26P9QyKS+ar/Kg2nt4jenjyzXh7teet28doqHvbN/hD1KhGRIsH+\n+fwNHCN6bbzH3/62TQC6t7NvXjsJ/sIhhBDiBE44hBBCnMAJhxBCiBOcaDjDPmoDYYzrs1FZQS61\nlz0M8IXJCDWdhbZdr+01UU+YHqGGs7qBOc02n/uyaePNR7gee/M2xi+ewXXjfh//LiKydgXzrfmC\n67GxylfUK5ROJCKDXbyH9Rjzs51ZVOeRWQ9C9ByuC0+Vd+dP//W3IH700HqbAqO/4Pq0svJIUvI/\njZ8k5jVyilAaRZhj3C2xZZzr4nPyicuYf6ulfHdByZgwHqAGMZvgGFBv4nN1/ar1nZy7cBZiP0Ld\ndtTHY5w7Y/MaXr+LueI6qkjj4gJ6fcLQ5kHLVT8p1HinCzumM+vlUfKpRNoPJaiLLS2jzisiMprg\nWDTuo667uYLa8e/+/b9j2vjmH3zXvHYS/IVDCCHECZxwCCGEOIETDiGEECdwwiGEEOIEJ5sGAuV7\nypQZsBBrjPJVUbZMmc2OlO48GNiMkMUcxcwzXdxY8LmvfhXis9c/b9r4/X/xzyFeVwbLIMZkf4/v\nvG/aWL/8SYhrS09B3CxwE8Xk0Bawquco+MdTFPv2hxj3VtCwKiKytH4R4ukIxU0fQ8kq1oCqk3cm\nCd5jL0XDrldgLCKSpk4eO/IL4stf+BWIL38SN8U8eYxGZxGRzQ0U8K9dvQLx+soqxEFhx4ShMi7O\nleFSP5utpt1I1GqhwB9UcLNCpDZATMd248xnnsGNBhevXYQ4yXFwKkr+r09zlcBYDZJBhH0kmdnx\nLdfFDlWyXa+m7mFJMt652sATBrgpKIvxnq+UbDz40q99zrx2EvyFQwghxAmccAghhDiBEw4hhBAn\nOFlMVznkJFPrhmVFuvRyYzFVn1HeyMUlNEqJiKw3cI3zM5+9BvGNF1GzOdq1iSarKZrLLp9F41iu\nTmR9FY1SIta0NVHm0DjFvydT+7Vkgmun7z9+BPEbb74M8YuftwbUpXU0ug6GqBWp+myyfNGugefq\nu8pi1GhSpZsd79mEgfOh/a7I6eFXnvsExE9/GjWc6TOoz4iINLsoEGprc6EK9/mBTfC62MTEkqr+\nmvnvOc+tgTrVBdXUWDSfoyZ75anzpo16BfvFdIxjROGr/uvZ/lyoQTFXRSgzTxc6tBpOPMVzzXJV\n2DFU97Tk98XwAHWw+3cfQvzFL30a4klik6o2tFb0AfAXDiGEECdwwiGEEOIETjiEEEKc4ETDyZU3\nYzrHtdVK0+7tDkNcww181AaeWkdfSq1u586LF85B/Kkvoe/mzPXnIH7tx//CtHH+HB5n/elnIa6s\n4Hp12MCCTiIikxlqQ1NVXGrnCa6bHu2gPiMikinPQb2NfoLlZbxfD5+8atpYO7MJcTpRfqgpJvvz\nxkf2PApcN9Zr0fUqnkdl3a7FD6o//5ov+fhRV/6WVg0TxTYbJcNKiD46LUl4WsPx7DOSq6S2eaJi\npYOUacOpUo+UdUcKlTS01bMJQFNV/DDLVeZNVXCtEOtF8/WBM4wzNf4VYjUcnUTVy/E4VXVeUWbv\nR3OG7yl2sH/v3cFCl2evo4YtIrLvW+37JPgLhxBCiBM44RBCCHECJxxCCCFOcKLhRAEe5kjl/cpm\ndr223lAFmVS1oVXlu3m4Zf0eVz7zmxCfffY31TtQn0mGY9NGt42azMq15yEeh7jG+9arf27amE+x\n3YEqJLX/+AHEQWY9NLUa3sPNS6jHPHcN87OlgfXQRAEWvYoqKo/SDHOnTe7bnFhaj0vVvywjVSiv\nsWTPY00VviOni3YXn/lCeWYmc/v8FnPUB+fqPeMR9pE4sW3M5/i8pilqKYny1Og8fyIiE1VwbDJG\nPTVV3p32otVk213sR732MsS1ChZcy3J7HuKpPGgqd2RbabQHu7aNmcpJmat8i57geeQZfgciIp02\n6m8Xzq9BPJ3g91LkthBct6T45UnwFw4hhBAncMIhhBDiBE44hBBCnMAJhxBCiBOcbBqYT1GMblTx\nsF5NGadEJPJVgaIM43oLP/Pb/+lvmzZe/K2vQdxZRkFs5847EAe+FcT6Q0zMt3fvPYifDFFE/943\nv2naaNVRVJ3NUexbX0NhslMiwt19hObQWJ3r4sZFiK89i0WyREQkQ4HwsI8G04navHE0tffDK/C7\nm01RZB0p810xskXcbvTMS+QU8c1v/SHEWfRDiI+O0CwoIjI63odY7QEymwh2dmwbmXKLLqqibQvL\nuBmlGtjhbXyIG3Zu3sIxYDDCvnnuEhZbExEJIuzPnTYe99IlTPh59hwmHRURuXQZN/0sKjN0u4bH\nyFXy0788ERwDEzVGBioDclBiuF67qDY8dHCMSFQBxQD3IYiIyOJiybmdAH/hEEIIcQInHEIIIU7g\nhEMIIcQJbpJ3Fsq0pJLMeWlJoaRCFVxTSSJrVVw3fP5XrGZRVWutb7+GCS2PnrwP8Xxu9Ybh0SHE\nD2+/DfGoQINqlNk2WipxYaeGGs3KAmo4Wzvbpo1UmdomQ1xrfngXzaMib5k2RiM0udVCvKdpFdfE\nD1K7NluvoyGt0cbrr4e4BjycDEwbaYl5jJwevvMnL0HcO3sd4iKzyRxffelPIL6gChkuL6EO8vhR\nSR9Q40ZjEcXA2MdxZEfpniIiX3vhCxA//9zTEE/UGOBHdoi8++A+xDdv4Tjyxps4zvS6Njnx7/3H\n/wDiLz6NxSErqrrc2TOYiFhEJFYajqcSgupkpklZEtFQJfzsYf+uqwSoeWANqDY978nwFw4hhBAn\ncMIhhBDiBE44hBBCnOBEwxFV9ChXhYPCCBNxiohkKklkrJLbrXUxUd0ffevbpo3FNdQxVtU6aDxB\nj00Uof4gItJqoo4R+rhu2lQ60fqqTUw5HWIhs3qAxznYQ49CEtu11nYNtZJY+QVuvfoyxFvv3jRt\nzFMsriQRXkumr+1sSVK+Jn53fhXXvGtKn1kQPG8RkRtPX7LtklPDf/Kf/yOIq6tXIZ4Mrf5y642f\nQXxmHfuir7SCes3qh3GOz++1Z/C4C2dQg5ws4xghIvKN3/pbEGsNcqw0nLykVmCqCsHNUvzM7i7q\nvvfvPjFtNBp4fduPDiC+99YtiP2Z1YbvbO9C/MLf+SzEFy5uQKx9OiIifk0ZayKlr2u91bNjU8Wz\nGvxJ8BcOIYQQJ3DCIYQQ4gROOIQQQpzgxoejFkIrypdSC0vWANWe8kIVFMtj9KXs79t149EevlZP\n0BOSC57H4oLVX3obKxCnqojR4yd4jEJUkigR8X28zXGqch55qAM1a1bT0lalQL+gfEpZjPqUiIiv\nvofBBLWluIpr5O0NW7BpXMdcVENVXGo2xv9hljqXTRvLJToXOT1UK/gd33z3TYgHx7YvFtoTEuNz\nM1IF2DzPiie1KvaTZIK+suM9PMbOA+vD+cM/wjxwR0PVxgj7TbtjtaTuAhaga6r8Y48eoWazuox5\n00REah3Um374B3heh7dehzhT452IyO1tzDf3SBWTu3oDNa5ux44rXeUBrDfQh9Nt4j2PSvJeNhpW\n+z4J/sIhhBDiBE44hBBCnMAJhxBCiBM44RBCCHGCk00DvoeiUq2KZqtCrCGpWUeBq9nGQkGTBI1Q\nS21bGShU7cbHKLLlPn5mEtnNC2traFLMldh5/TlMQvjSn/w700ZcTCCOlCA6HeHfO20rVFZC/KoC\nZbYaKWPY3S3cECAi0u/j/Zh7KNSuXMP/PzZ71rQZF3jPjvbx3CsztQFis8QIO7HmMXJ6GB7gpoA/\n/r/+AOKH21jYT0TET3BDyuuvq6Suqk+kaUmCV/XMf+fbfwxxRRm3n//0Z0wTcaUN8WCOz++dB2im\nPDjAAm0iIvEMz+PJ9j2I797Dz3z20zax8H/7T/47iH/6kx9DnB6jEXQwtxt4pmqD0p2XcZPED1/Z\ngrgZ2o0HUQU3AQRVvIdttWng7IWLpo3f+b3/DOKS0o//D/yFQwghxAmccAghhDiBEw4hhBAnONFw\nKiHOaxO1HhnUbJLIXCW4nKg14CDC9ctqxeoNUYTtVhpocup28O/be6jxiIhMNlGjWT33FMSPdzHx\n5tOf+6JpY7SHRrA7NzGp6HiEZsowUEk2RaTbRV3HUwlRtx7jMR7cLzF+VvF6O2uok60sqmOUJAz0\nDrGNhSN8hDZX0RR3tof3T0Tk9tuoAXz1H5i3kI8xZ9bOQHz1IuqchVgtNFTF0QKl2fgBjhFFbg3U\nFT1ORGhS3NhAg+VXvv5100a7gc98t4YJPt9+E5OM3ryNxdVERNY3L0I8U8XSAqU/v3nzXdPG2zcx\nuW7j4g2InzzB81ro2USkqxXUUxstHAMPt7FQ3MHj26aNvX0c82aZMugqs/hW304ZL36tJMPpCfAX\nDiGEECdwwiGEEOIETjiEEEKc4ETDWVvBeS05wD3m08yu+Y7RIiKFj96NUPlSOh3r96io4mjTMe79\nr0fq8mN7O15+6SWIL19XCfMeoR7h+3Y9s6GSDgZKn6rXcW16PLIaznSKr6WqiF2rjm2++Olrpo2a\n8vekAXodsgQ9CdOHVsPxh7huvtpAX8Onrz2Nf++tmTZe2bprXiOnh8M9LDD2+V99EeIXv/xl85lq\nFf0eodJsdAG2vLBjQqCS7epChdMYn9+DR/Y5O5yhF+VwH6/ljtJsnuzaRKStVSxsJlXsE14FNZw4\ntR6a73z/RxBfuPIsxOcWUY+q+XZsaijf0XyGyTvvDFArbpX4+7ICx4DtIyzsuLx8EeJJYr+XP/7+\nTyH+r/7xPzLv+Q/wFw4hhBAncMIhhBDiBE44hBBCnOBEwzl/DveLdz1c87z9ENdeRUR2VDGlOMP1\nylYLT308sb6TLMf1yEDNr4d7qCUNRzZ/0yzBdoNCFWhq4f74nW1cExYReTRGLSQvUOdZW0H9yctt\nzqOjPuZGqzbxfvS6qKVUAvu/xFyteUuI2tJ4jp+JR/h3EZFmju956tw6xBvreC0PH1lv08Ge/b7J\n6aGpCm4dDPD5fvX1V8xnVlexn6ytYm7EJMFn/ugIvWkiIqJ8YaHqJ5uXUFs5t4B9QkTk8U3MLzYe\nob6yuobPc2OpZ9oIaqiFTKZ4XmfOnId4+4nNLbd/gOPImQ1VgE4VrBvN7ZggIX4PSY79u6q04WpJ\nUbv4YA9f8LHPrynPUTxH7VhEpLCWqRPhLxxCCCFO4IRDCCHECZxwCCGEOIETDiGEECc42TTQWVAG\nTCUaL6yioUtERJpontrfQXFvpgqhhRVralJvkTxBUS3JsM3jqS1a1lSGytkEBcLpDJN3xoktLpap\n14oCr3c0UAXYOjYRaaeDiUenU/zM/gGee6tlE6J6ylznpaj2VUI8rvKz/eV7VMGmi09dxPOaYJs/\n+MHbpo3Xb+6a18jpoaoKFc6/Q24FAAAgAElEQVRnKPC/9JItQliogomdBj5rSYIbdmZTa34O1f/H\nFy6eg/iZz38S4ivnlUFTRPoPUcDfPsL+W1H9/coSbiIQEdnbw81Iz15/BuKnn70O8f/6v/xPpo1Q\ncCNVojYWxTHGRVpStLCG90wXT7t46TLEuw/fs2342J/rajPSjRtoIJ9N8NpFRM6dWbXtngB/4RBC\nCHECJxxCCCFO4IRDCCHECU40nLCGh6l1cP1ysWXnvXCK+kpUx3XjgSr8JZlto17DtcVMrT1nc1x7\nrjTs7YhCPNcgQG1prpIMxkmZMQoNV54yShVqvTazOTMlUiZNqeBaa/8INZxpbI1i3R7qXKHSdHx1\nrROxRtidfUwQeKTMssMxGtq++z1bfGqHvs9TzUTph6Keo6//1jfMZ/IYjY2B0mxylcC3CKyuG6jn\ns6Z03u0+6j7DPhY5ExE5nOJxvRoKle+9dgfigx8rY6SIXL6EGs3nnroKcayMoHXVV0VECmV01eZR\nP8CxKC+pcTbN8Z6FGV7bhbOo4cxGaHQXEfmkKkL501dehfjJfdR9pjqrsogUE6t9nwR/4RBCCHEC\nJxxCCCFO4IRDCCHECU40nJFOAhm0IGw1rWgR1VHoaCpTSLeL65ejgd23Pxpg4sjRRPlwZhi3K7aI\nW00VcUvnqC2FIc7ZlZIpPFLFpzwP39RQiUhLai1JqtZnK3VVgK6H69mHh6i1iIgMld7UWcTrnaii\nbrfu2TXfd994CPHaIupCa2fxPMS3BZuWuzapIjk9NFsqGa/SJNsrtvjfXPWbmvpft+Jhm0XdetGq\nDXxPPkNPyHCIBRaDhvXmrV7BZJxXGujDuXUXC7CJZ7WkSCUvfbz1AOKl5YUPjEVE4ilqIfM5ap9j\n5cuZl/hfkjlqaWEN+97axgrE97dsIt2dB3i9sxGex/tvvQbx0hK2KSJSLCya106Cv3AIIYQ4gRMO\nIYQQJ3DCIYQQ4gQnGs6j+xjP+6jHtFes36NWx33qXZR9ZHERT300tuaOfh9fOzqoqBjfH+R2vTZX\n1YWyTOU0UkWPymZwz8dN9EGI5z5VHqLC3g6JVLGpdIKF3jLljci0b0dE+iN8j67Hdqh0sHu3rYbT\nP8C153iMjax3MffUjQubpo0SuY2cIiZD5W9RRfkiT3VWEdnZQW3g1tv3IK6pPH6Vri18tqyKuG0s\nY35B7Stb6lpNVtl9ZKbyJ66uou6zuWH1ia3tbYhv3nwH4ovxJYi1fiUiMhzi/ZhMUF8ZHKMeVabh\nZDF2pKCKnpq33sQid2XF01ZX1yDefA7zwq2u4N+XV2xuuVrV5m08Cf7CIYQQ4gROOIQQQpzACYcQ\nQogTOOEQQghxgpNNA1mE4lVS+SzE89yKan6KhqxaF4X33gpuPFjwrdK+OEGFsH+IwmR/HzcJTMf2\ndmQpbjSQAufoPMVjzKbWxFqpqASgIR53OMM2pqMSI2yBgl/bR/Nk7qPImCT2WqpN3ABRi9DA1qvg\nMS6LFW6f/RQKhNef+xTEF596CuIXPm83czx6YgVQcnrIVbJZX/3fGiZ2801HJc595Sffh3h7B/u7\nF9mEly+88CsQf+kLOI4cH6MQ//pf/JlpYzzDc7/5AI3Md+7dg3g6sc+vTsZb66AZcjBA0/VQFXkT\nERkPcLOCzs0ZBvhKt60M1SKycQk3JywsnYF4dQMF/o1PP2vaWFTJOysqaWqgk6iWGGH1mPhB8BcO\nIYQQJ3DCIYQQ4gROOIQQQpzgFYVyNhJCCCG/APgLhxBCiBM44RBCCHECJxxCCCFO4IRDCCHECZxw\nCCGEOIETDiGEECdwwiGEEOIETjiEEEKcwAmHEEKIEzjhEEIIcQInHEIIIU7ghEMIIcQJnHAIIYQ4\ngRMOIYQQJ3DCIYQQ4gROOIQQQpzACYcQQogTOOEQQghxAiccQgghTuCEQwghxAmccAghhDiBEw4h\nhBAncMIhhBDiBE44hBBCnMAJhxBCiBM44RBCCHFC+FEcNM/zj+KwbijsS57nQTwdTyA+ONyHeHFx\nwbSRxTOI640GxEGliqfh2f8lcsHzCOypfiT4Pv/vOU2c22hCXK/XIdbPu4hI6OPTpr/zNM/wAyVt\n9I8HENf8CsRNH4ez4Xxq2vAb2E/qVdVGE6+t2+2ZNo6ODiGOx3OI9RCQxIlpQ3VFCUK8P5UI70+3\nWTNNnFnBceLxzg7E4xjvaadjx5U0wbMdj48hPrvZgTiK7JQRhvja//6vXjPv+Q+wpxNCCHECJxxC\nCCFO4IRDCCHECR+JhvM3fc1+PsF10sNHdyB++A7+XUTkeDCG+Iu/8TWIO3W9xmvvsacWjv9mfwvk\nr0sUoN6QpahR5JnVaL0KaiXzNIVYaxhlGk6vjbplR+kt8RD7SD6NTRuNCPWmbgPjhupHrUpk2tif\nomaTFxjXaqgTrawsmzaOjo7wM+q4G2dWIQ5KxOHV1UWII9XG3YdPIK5EJfe0h/ewhaEsdbsQ6zFE\nRGQ8GZvXToJjDiGEECdwwiGEEOIETjiEEEKc8JFoOEVRYlb5JaHs2nwPX9t+eBfi13/8A4iTKfp0\nRESiFu6hnw5Q5+ks4nqu9tyIWG/Ox+VbKPNtkI8vlRCfI089VwvLS+YzY/VMRxlqNqnSdLySfnRm\nHXWN9RU8zt3b70O8HKL+ICKyvrEOsZ/iufvqWbTaqMhStw1xEShdSOkejSZqTyIigY/Xu7KGOk9N\naUfDgdV10wK1s24Pj7uZ4j0MSkb7MML3VAPUn3Lt5WmjL0dEpEh+fl8lf+EQQghxAiccQgghTuCE\nQwghxAmccAghhDjhI9k08MssEhdiBbRkjoLpk4f3Ie5o81kPRUkRkd2jIcQHW48hXjt3Hj/g29Sc\nWob1/F/e74H84uh28PnUpsXVVRT3RUR2Dw7wM1UUp4+P+hCvLa+YNqpVfKbrdRTWN8/hhgCdiFNE\nJIlRrK8IGlKrKgnuZGoTgJ7bwOsrIuzzFZUQNI6tAXV5CQX+0Mc25nM0U7Y7duPBVCUnHR6jmXQ+\nR8F/admOK/UmTgGhh58JY7yW2djej3Rekpz0BPgLhxBCiBM44RBCCHECJxxCCCFO+Eg0nF8mtNFT\nmzxFRPYOcf363r0HEM/V39s1XDcVEZmMsPjUuz97FeL1i1cg7q1vlp3sB4W/1Noa+f+PZWXs1AUV\n4xkWCxQRWVOmzUYNdcuqSgh6ZsVqOEmiChfu70LcVtpSGJUUIYzxXKNQJbT1sVNMJ9jvRMQUT/Nr\neO7zeKpiTO4pIlJVGtZogBpts4WaTZapAnUicnCImk01Qs1Kd+e45DyGoxHEvrq4eIDHjUuKybVK\ntLKT4C8cQgghTuCEQwghxAmccAghhDiBGs7/Z7QuYtdaHz96BPHdBxg/vI0F2JbbLdPG2WVcJ916\ngF6eN17+c4g/+5WeaaPRUckMKdmQvwa+8prFc9RsshKtINU+kxnqMWGA//sO+oemDU+wbxVK13i8\ntQVxt2V9J40Q9dHBHJNiak22UrNDZKIKziXqej1VYDJP7ZiQB/haVRd6U/rqZGrvaaWKOk8lQl2o\nUcMOXq1abfi431cx3o9WTRVgC6y/z4wrHwB/4RBCCHECJxxCCCFO4IRDCCHECR+RhqPzjf08YsJf\nQ3AodKhfUOdR4kPxPnROxs/keWreodd8hxNc8360g+vVOzt2/TrL0MdwdhXP690//ynEq+tnTBvX\nPveCegW/fr/AaymxFJl/UdRHxNP39OfB4/89pwlP9aNKBZ+jsiKEaYZ9YD5Dr8pCHTXKqCTPX+ij\nzjGLUU+oVDGnWzy3OcziAeYoq7TQD1SpoM7hRVazyFLUU+rKU5Qor0q7Y/XUWg3P1VM5zLQ/Jomt\nDuQpzUa3KYm65xOrA2Ux9r1KiPqxLuyYJHZ8G4xtwciTYE8nhBDiBE44hBBCnMAJhxBCiBM44RBC\nCHHCR7RpoEyN/rBPfMimgbImTbJKFQsKYKUbBNRGAk90bD5gXjl/8SLEjXYH4oEualQior/5EBMV\n1kMUDMMZCqRvvfR908bS5hrEC2cv42FTvD+e3hEg9nvIVbJD/6/+1Zbt1SAfY3xlbCxy/NLrTRTR\nRURmnipSphI+ZmMlaHt2aFpfw+c3PVAPW4p9oKmKqYmIzIcoxnfXURSfTD5cAF9ew8Si8xEeN/Bw\nc0MU2fOoVfEezaZ4XtUK/t2vWDP4sbpnSYIbC4IMx7fZrKRQWq6K2qmNB6HaRDFL7EaMvf092+4J\n8BcOIYQQJ3DCIYQQ4gROOIQQQpzwEWk4f/V5rtSE+P+izGwmam05V4k1E7Xmq01fIiKeOTAKDuao\nnjWKLSwsQ/ylX/8KxG+89i7E9+5iYk4RkUwlALwdbENcu7iB73/vlmnjje//KcS/+vdxLbrewHXi\nrERb0XqLfkv6c+hzWgdjBtnTxeO9D0542Zxb82+ri5rNTBkZWwFqB5tnFkwb1QY+NwHWH5OFBvbf\nXkMZIUWkvY59ca5Ex5vbT7CNHuqtIiLzMR54NkGtJFLXkgysWXI2R/0lV+NGoAynoxEWaBMRSZX0\nG2d4LSs9TO652LH39NYQEwcvLeB79HDWKdHn8sQmST0J/sIhhBDiBE44hBBCnMAJhxBCiBM+muVz\nk/Hx5/mM9tAoz0jJR9IC105v3UZdYzrFRH6fuHHDtFGt4iKm/yGmkbywGk6ubvOLX/w1iB/cfQzx\nP/un/8y0kU5Rb3qwh4WTqg3c63910f4v8d4PX4Z4RflwPvFFTO45Ebv2HOUq2Z+6H4cTXN+flxTj\n0nrUpbVL5j3k48s8RY3m8BCTzTZUcloRkUXl34hUn6i1lMYzGZg2Rkor0Z0+SPHv86F99lZUccP3\nbt2FuFVD3aNVt5rFfK4Sj55BL4+XoQ8nLUmaqeu6DWeqIJtKRLq9g9qSiIjkeG6tLiYJnU3RU5Qm\n1odTr+F41W6iDnaofEuzuf1u2y3rEToJ/sIhhBDiBE44hBBCnMAJhxBCiBM+Eg0nL3TOLvsek/dM\n5QUy6cZKtJWHjx9A/K/+9bchHgxQb3hxH/OViYh89cu/AXG1ilqJvpay8mNphq+22rhv/Ru/8w2I\nb79307Tx3T/8DsQDVQjp3cfoy1nw7NpzbYY37Sf/5t9CHC7hWqy/ZgtHjft4z6Ic1563Bo8gPh7i\n+0VEZjNcB770d/9r8x7y8WV1EZ/fdIbr/O2WzR1WKM9bEOKzWK+jdlBmq5soHTNOsY2qEkZuXH/K\ntLG9vQPxfI4HWl5Bb5ouHCcikgtqNA2lP8UT7O9B3Y5NgY/9ZnyI/eRYaaHdjvUDjSZ47lmO51qN\n8DyT1Gqym+fPQZwrYexogN9tntsRrre4Yl47Cf7CIYQQ4gROOIQQQpzACYcQQogTOOEQQghxwkeU\nNxEFs7KCY0dHBxAfH6G5zAtQ3Nres4L/j1/+KcSvvPUziAeHaJ6clxQXevrZZyBeXcHkf0GAt3Aw\ntAWc+n08zsWzZyHeOLsK8X/5j/8L08bDx+9D/Gc/ex3i+RgNXLce4SYCEZHGOr7n4M03IZ78Pr7/\nyhc/Y9o4UkkEJ8qgN/fwWuPEmt7y/K9RpY18bGgpM/SNK+chrjfQPCki4qt+sv1wC+I0xeek2cI+\nISLSH+Fmk8DDjQY6Kezw2Ca83Nvdh9h6IVFoH41G+g2SF/ihyQQN5KMBnmenYZNbxoJtFB4K+oEq\nctdp2zbqDbynYahMnG00jwZ+iSldbQK4++AhxF6I97gS2DaGJUbfk+AvHEIIIU7ghEMIIcQJnHAI\nIYQ4wZGGo4oN5VrDsZ84HuBa6w9f+hHE95+gwXB/gNqBiMjRGNdwfZWYrjZHw9buAR7zL4/7Q4gv\nXkSjlDaCPn60Z9pIYtSGphM819EQ46jkW7nxOUy0+drtNyCOh6iLPOrb5IeNCp7r2S6u8d59+S8g\nDqr2/xF/AxMVHqeoWZkV3sIWtZvPra5DTg+tCn7LzQb2o6iCOoiISLeHz432Qh4doGb71jvW/Jyq\nxLHVChqVF5tYPOzJY0yKKyJysI99fJZiHxho3adEXy6U97Hfx4JsWgqO51YbbjTwHi4udfGw6rhz\nlfD2L88D+/x0hklFCzXupiXGT90XMzU219V3W0YY2T5+EvyFQwghxAmccAghhDiBEw4hhBAnONFw\n3noH/S9hqJLKxXaN80h5V/ojTGb3YAvXZ7urS6aNxS4msFxaxiRze++jF+CdN1EXERH5zncxaWa3\ng20Gau/7PLYek1gVLfo3f4RxpKZ97csREWks4z371POfgPjVH70H8aQkjejNA0xcWM9wfXYhxb3+\nt3/yimmjv4Jr3oc+HieK8e9pYteNJxPlVfpvzFvIx5iz6/h86nX/hR5qKSIigYf9JFrG96yvYP/9\nd3/yfdNGnmMbvbby4m1hv1pbwGdRRKTXRd2nv4u6x/4u+td6CzZpZlNpwV31nnYT9ap2F/UZEZFm\nSxVpm+J53Ll9H+IgtDrJRGlDsRpH4zl+L0Fgf194apyo11DnzTw1VpcUcUtKirKdBH/hEEIIcQIn\nHEIIIU7ghEMIIcQJTjScl376EsTTAeYeatbsXu9vfON3IE4LXFt85Y13Ie627brxNMe1xY3VNYiT\nHVw3PR7bPGiTW6iNLChvSrOL595asMWIak1cJ+32cC1aF1fqdHCdWUSk3sL8VF/5jV+F+HgfNa43\n37xj2sgSXPN+0FdakirYFG5b/WV4hK+lbdS0/DrmmnuscmaJiAzU909OF4UyolSV76ZMK0jG+J1X\nVS7EIsI4y0s8YD4ex7xDFSC7cOGSaUMXWDu7hbnSqlU8Rqdrx6ZAnfvuLurJL/7qCxCvb2yYNtIC\n+97gAP17R/vo7Tno2z4TBqgXryyjVqRzFuaZ9fJ0WzjWHCkfUuHjtcZTq9dkJTrtSfAXDiGEECdw\nwiGEEOIETjiEEEKcwAmHEEKIE5xsGrhzDwXs410UxK5eumo+U6+jWPfkCRZYu3/3AcStJorXIiLz\nBDcBeAPcJDDtK7HLt1lEn7qCSTOvrKAw11amr91dFO9FRBYWcV4/cw6vbTjA86xYz6bUlOmto87j\nb//mVyE+PLLJO3ce4T3cn+OBGsf4mdWONb2FHgqRm200uTXX1iF+fO+eaSOe2MJY5PTw4CEmzm01\n1fM8tAJ3r4rGRV2ALFNm8EZJwbF4iv11dQU3ClV97N9XLm+aNqrqPPwIx42K2jRQr9tEpL4aJ4op\nPs/zAW5ESLp4XiIiS2ew//opvufCOSzSWK3Z/jwYozm+UlEF2TyM0xLTpjauZ8pMGqgNXUVqE++2\nlNH1g+AvHEIIIU7ghEMIIcQJnHAIIYQ4wYmGMz5GXWOiCgVVGzbJ3vEQP3P/4T2Ie13UF7KxNSR5\nM1xv3Nq+jfETLMbk+XZ98h/+3n8EcT46hPiPf/Q9PM/XbdGnpS6uG2/fwjXgzY3zEB8nmGRTREQi\n1F8Wl9DE+uz1ZyCOf9d+tf/8f/yfIZ4O8Z496ePas5QkDJzHqPuM9rFw1ob6Xiola+DLqz3zGjk9\nTKaqoKKqoBiXFAtbXMF1/jxHPWY2Q33h3DksdCgi8vabaMKOQjzumXU0da6slCURVclm1eNZqWK/\naZSMTdr4KVPULacD1FsO97DviogUPva9eg3b1MfttG1S4MEEx6Iiw3tYr6E+5ZX050RVi+vU0WCe\nqXvcadg2IlN18WT4C4cQQogTOOEQQghxAiccQgghTnCi4cRz1Gwmc9ynf/suaisiIv/nN/8lxD/6\nPhZk8gpcW9xRe99FRPbuP4Q4Uv6WRBWOqqzbQkl/+oMfQjwfoO7z9q2bEI93bCK7/h4ep7eE67N7\nKknm4Nj6GBZ6uB4bZ3jc733vLyCud2xBuoVlLJy1n6D+MpnjeTweWl2sqKq1ZnWugVqv7i3ZexoE\nTh478gvCD1D4mM9QB6iWan+o+1Rr+L+un2DnzGLrXRkeoe9kMkKt5NL5KxDXq9ZX12qgv6e7gP0q\nSZU/KLPFIXVy0uVlbHNXFXXb2kOtRUTklTdfh/ipp1DH3d3Da3uyhck9RURSwXva6+B5RKq4WrVq\n9ahUF5CcYZ/P1S1sLFr9dTCyY+9J8BcOIYQQJ3DCIYQQ4gROOIQQQpzgZDG9u4jr+Ima5gYjmyfo\n7ddeg3jn7l2IfXXqjdD6PSo+riUXMa7H+so/cPaMzb20qAq7HU1wffbyxesQ388wT5yISP8QtZKs\niuugO8pDNJlYH0P/EL05XoBrrzMPj9ufvG/a8Cu4Xp0H6v5UsM2J2KRuWYqvNVWbrS7er7JiXHlh\nr4+cHtaX0XdSjfA7blSthlNvYF9LlTYSqWJhnZrVQq9soves18Bnb0P5u1pVaxDpNFHHmPkql1qO\n5z44tudRU3kbowaOPdt7qGk8PLSFHd+7jf15e1cVZDtW+dgSq5N88sYZiFs1PI9sonyFub0fRYH3\nvaaK6WXKU+WV6K9pxgJshBBCPmZwwiGEEOIETjiEEEKcwAmHEEKIE5xsGmipTQNhG4v6xAfW6Lh/\nE02b51rYhqc2BAyn1qQ481HM8uooGFY9FNH2dkoMWn/2M4jXVGGoA2VGO55aw9pIae/Tfb1JAgXV\nMCgRXSMU92ZqA8ReH88j861A2AhVMj9fme9q+jMlleAKNMaNx3i9A1XkbmGpJFGndpORU0Whnpua\nSvgYhfb/2KiKr82GKGgnCYrT3bYt/vf888sQ6z4RRdhvwhIDaparZ1ol0ayqImatVslmJGUoLXL8\nTKTuz9vvYtJREZHxRBVDy3AMnM/x75WgrBBcFc/Dw/PKfbyng5KxaTjB69djTxzjGJrO7Tgbz23S\n45PgLxxCCCFO4IRDCCHECZxwCCGEOMGJhpNXcF4rMlxrrJSYAyO1pnu+gwWcUqVRDEvWJ4NOC2K/\nghrOdAeLvM371qA1PBhCvJ/jufbn+JmLn3nOtLG9h8bP/hEet9VCTWs2sZpWEinDmkq0OVXJD33f\n6iQ1df2FpxIVKs0mCO3j4ae4bp6rNfHdPdSSSmpxSVihhnOaiRN89oZj7AN+GzUdEZFpH/uRTpLZ\nqKM2GvhWf+kfqP6qNJzjEY4BSWYLsBWq3+gibpEaVyZZiT6hnulYFaRrqCJu29tbpol5gX1xHijN\nRulPgdFXrUE8VbputYJtHM/sGLl9gIbxQtRxVJJkz7Mdul79+acR/sIhhBDiBE44hBBCnMAJhxBC\niBOcaDh9tX47n+BaYzO265Mr6xsQH9zHwl63792HeC+x+8MXF1H38WvoQxnnuH6ZJVZbSFUCvNlc\nrZt6uI68t40F2kRExiNc4y4S/EyjimvecYmnyKvinvt0hudVaaIOVGTWQzOb433PfTyPOFVrwJFd\nR6/U8DxaDdTJ6ipO1LWKiPg+/885zewr79nGKhb705qOiEia4zO9uIR9czjAz6SpbWOuNAqV71Pe\nva0S/Hq2D2i9+PxFHGf8Fj7fs7HVLDJ1HqkqFldVx9CarYjIzcc4fl1awUSci23lXVy0vqTxGHWf\noxSPEypPUZlX8Ui9lhd47p6aIiLPJuoc6yShHwB7PiGEECdwwiGEEOIETjiEEEKc4ETDkanKA6SW\n/FLPagVjJetsqbxnW6oQ2Cguyful9u0HEa4LT5SHpCjJ8TVNcc2yUMXDKkrneLxnNZxU6Smeyp22\nd6SKtnn2PIoMjxvVUY/qqD33unCSiC22FKicV3XB78kv80ep6/XUcQt1T72SNnzPzWNHfjE8fPIE\n4ijCvqk1DRGRc+ewaJte9x+MtIZjtb9Ae2SU5vjO7TsQhyX5BJ88RE/M8iJ6dbpdzP1369Zt00Yh\neG6//fe+AHG1QL1loYceIxGR+gD1lwOVCzFX45m+xyIigxFqv+M5+vcm6nvwK6hPiYjMEt1fsW9q\nn93RyOpRy+26ee0k+AuHEEKIEzjhEEIIcQInHEIIIU7ghEMIIcQJTtTb0EMxOlHi9WhqjUOHAyxS\ndhjje9IIT71Irag2U6YmTxkfk0InvLRtNLsoAAYBvkcnuCxKpnAj1us2VFyWeFN7JXNdPM2cl91E\nkeW4kaBQx9FtlBk0Pb2hwcP35OoYqfWJSVr2Ijk1pOp5PjhGIbnTwMSUInZTgO43uUoaOZ5a46d+\nHIscRfF2HdvYPbRtvPYGGi6b9T2I5zNVGK2kCGFFJdJ85xa2udbAQnHtpi2etr6O7zm4vw2xp5KK\n7u7heYqInD2LhttMbXqaq40XkzEa8EVEUvWZTN9TlQA51m5bERmXbdg6Af7CIYQQ4gROOIQQQpzA\nCYcQQogTnGg4o+EI4sEADUrjkTWKjcdKf1HSQaeH2kq1bk1NGk8tAtdVkaOoxBil9ZVIaUd6LTrL\n7Xqm1nBEGcf0n4Oy5JYqSWiWaa1EG1TtWmui3pOJNoLitYYlBdh0u7UartdXtbaWWwNqtfrh3xX5\n+LKwhPpDp4OJY2uRfW4OB6gf1OtoWkxifE7iEuNyGGG/qFSx/8YZ6i+7h1azmKXYxmIbjZ5nL+O1\nJYnVGwdDNGnee4T6SmVFGagL20aroQzUq2hA7dRxfBv1UdMWEbl3/x7EV66dhzhWxdPizCbv1BKV\n1nnOq6Sh9Zo16c+nsXntJPgLhxBCiBM44RBCCHECJxxCCCFOcKLh7B8cQKzXa2czuwYYqyJHUS1S\nMa4lTqdWB9LJJ43PRsVFUVKALcP1V18nvGygHqF1on/fMIRlOg+0UZK8Uyf81Ewm6DnQGo+ISKj1\nFeXD0ededh5WG1LvUX+u1WxiP2o4p5uhetbyHLWTjbVV85mK0mwmyhPXbKBW4IX2+fUCfLiiiko8\nqfSZydS2Uamj5thaUgUDfezvaWj1l1oPryUPcWwaKs/R1csXTBvpNura6RjHr+PRIbbx1FXTxqOH\ntyBOlO6li6eNBtaXlKvfHK1GQ8U4zo5LiusFDZuc9CT4C4cQQogTOOEQQghxAiccQgghTnCi4SSJ\n0mhUwrEwtLmG9DJ/Vf9K3DoAAAYsSURBVBUc09JBWU0v7aHRaYAypdmU6R666FNQUfnGtDeg5Fq0\n7qGPU+aZ0Wg7i85z1uuhnyBJdE4okbnSxTLl7dGaTdl5ab9PmqrjZPq4to2y+0xOD40mrvNnqhDa\nvOTZCyPtZ0NtQPfVsv+FfdW1wuiDtdB5bs/DU16zRhfPYzjUfiGrQe7tob4ShqhhLNTx3BvKMygi\n0qqhZrO20oV4v8CijI2GHVdWVzGX2lDln4z1mFEiA3dUwbl2B693cIyeo/19W2Cy8FvmtZPgLxxC\nCCFO4IRDCCHECZxwCCGEOIETDiGEECc42TSwtITili8ogGVZWaJJFAS1wD2boejmBSVmSVMcDNuM\nM4yD3BZg09iNCKjM6fMW+XDTpvZX5iVFjlJl6sqzD068WVbkTCfvTHJlalXX9vMYP03xOPngDRIi\n9nsgp4taHYV231Mm7NgWVKyqvlVXiTc9wWexEpX0RdXHO91FiGcDLAQXh9ZQHlbx2ZvGmNAyCPC8\nEnspEk/xGd+aoZC+uLmJbWztmjbqajyrtfF6V7pont0/eGDaWFTFIfWuilGKJ3/9zIZpIy/wuJMJ\nbrSYjDFeVJsMRERK8pueCH/hEEIIcQInHEIIIU7ghEMIIcQJTjScTgfXGvNMJ3y08948xrXDwQST\n3WkjWVCy5mv0AxVGyjyZlmgLuWpDazaidCKvJAGocZyaP+Pf86ykiJv63yAvlB6liiCVGT9zbcJU\nTjB9lmVaS6He1VAF2CpKS/JLdKCywm7k9FBRSXEbKuFjqYFadb4g0KZrfF7T1OovhTrucIjP2lQZ\nH/UxRURqNXz2YiVAJFOMJ8dWxKmEaI5sLypdQxVyTCY2sXBQwX6ki8kVKtGuNmSKiFRVX+strmAb\nAzSoer69H7MhFsOcTvA9NfXdlum6poLkB8BfOIQQQpzACYcQQogTOOEQQghxgpPFdE90YS9c84tL\nNrvP5rjuqROAas9IWFL4rFBaSKx8KHNdsKgku50uSqY1CZ1EM0/teuaHlCwTrZQUJeukumhb4WHs\nh/iZKLDJ/sx5aSnNJBm112LkKKUl+UrT0n8XEUkTJu88zTSVRhGqJ7rsv9ia0vpGI9RktZ+rUlKk\nr66Shur3qJyZMlWJJ0VE1lbPQzxTOk+viecZraC2ImIf6URw/NJFG+utpmkjUoXN9KCQqDFgecUm\nyKzkOHwHKnFwtYrXUhR2nG00sN26Pi/1vZQVuix77ST4C4cQQogTOOEQQghxAiccQgghTnCi4Wg/\nx3yuPSN2z32schzF6jN6/7z2pYjYHGZ6nbim1oD9sMTLo3QfrXPoa/N824Y+D637VEzxKctshvdD\n50oLVJu2oJU99/kc13Qnyi9Qtuder8Xr46Yqj5bRdESkVrPr8+T0EKnnyFeaRSWww8qH9QHdjyqR\n1SD1M5+rXIA11Wa3bXUPLdPWKqgL5apqWaOFfxcRSdRYNJtOINbacKNi70ekdLDxBNuotdG7OI1t\nwrKpOo+owHumi0f6AfZdEZFMdc/JFL+Hfh8LwZXlaKxUrM51EvyFQwghxAmccAghhDiBEw4hhBAn\ncMIhhBDiBCebBnQiSb1JoEyI0gnhTMJHJYiVlTgzxcGUqFgoBVEXKCs7rk5M6IkuSGbFTl+fqxLj\ntZhflCTN1MKcvpYP21QgIhIpIfbD7k9ZEkbdbkVtAGhUVbI/08IJCQDJqaFe0QUU8Tkp8pLknapf\nmIS+evNNyTOiBexCbRro1jHBZatErC9UIbjpXPVn5WzOEyyuJiLSbuJmBJ27Ul/9uKQgXZTg/ZhO\nlXnUxw08+8dD08boAJOV9nrLEB+M8X7VtDNWRIoC79HRIW5eGKrNDPW6TSJa9tpJ8BcOIYQQJ3DC\nIYQQ4gROOIQQQpzgFVpAIIQQQn4B8BcOIYQQJ3DCIYQQ4gROOIQQQpzACYcQQogTOOEQQghxAicc\nQgghTuCEQwghxAmccAghhDiBEw4hhBAncMIhhBDiBE44hBBCnMAJhxBCiBM44RBCCHECJxxCCCFO\n4IRDCCHECZxwCCGEOIETDiGEECdwwiGEEOIETjiEEEKcwAmHEEKIEzjhEEIIcQInHEIIIU7ghEMI\nIcQJ/zeMD25e2cSBiAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "b54f326c-917b-422b-9c69-a232422a0cef",
        "id": "BX6IQrHzuO0h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0dVdwiD_uO0m"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. One hot encoding of output classes"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WrGqT8fAuO0m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to one hot encodings\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ouoCAL6bus-Y"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Our Star Model 😁"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Zernbsu-us-a"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.1 Architecture"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C3Z8Z9UNus-c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ElrmRftEus-h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "CLl-VSklus-p"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.2 Training (≖ ‿ ≖)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c213891b-99c8-4ecf-e479-1fcf59a18e99",
        "id": "tUyut9Rhus-s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "50000/50000 [==============================] - 26s 511us/step - loss: 1.8910 - acc: 0.2825 - val_loss: 1.4262 - val_acc: 0.4684\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 24s 473us/step - loss: 1.4558 - acc: 0.4731 - val_loss: 1.2817 - val_acc: 0.5373\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 1.2397 - acc: 0.5650 - val_loss: 1.0588 - val_acc: 0.6263\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 1.0986 - acc: 0.6201 - val_loss: 1.0068 - val_acc: 0.6468\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 23s 454us/step - loss: 0.9926 - acc: 0.6606 - val_loss: 0.8894 - val_acc: 0.6952\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 23s 455us/step - loss: 0.9197 - acc: 0.6891 - val_loss: 0.8712 - val_acc: 0.7033\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 23s 457us/step - loss: 0.8605 - acc: 0.7109 - val_loss: 0.8493 - val_acc: 0.7149\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 23s 455us/step - loss: 0.8059 - acc: 0.7326 - val_loss: 0.7835 - val_acc: 0.7392\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.7696 - acc: 0.7456 - val_loss: 0.7637 - val_acc: 0.7455\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.7370 - acc: 0.7559 - val_loss: 0.7906 - val_acc: 0.7459\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 22s 450us/step - loss: 0.7125 - acc: 0.7658 - val_loss: 0.7891 - val_acc: 0.7345\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 23s 454us/step - loss: 0.6906 - acc: 0.7724 - val_loss: 0.7761 - val_acc: 0.7555\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.6631 - acc: 0.7814 - val_loss: 0.7624 - val_acc: 0.7518\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.6564 - acc: 0.7862 - val_loss: 0.7846 - val_acc: 0.7540\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.6273 - acc: 0.7933 - val_loss: 0.8109 - val_acc: 0.7494\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.6210 - acc: 0.7977 - val_loss: 0.8249 - val_acc: 0.7580\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.6150 - acc: 0.8010 - val_loss: 0.7893 - val_acc: 0.7448\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.5949 - acc: 0.8079 - val_loss: 0.7933 - val_acc: 0.7574\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.5908 - acc: 0.8093 - val_loss: 0.8160 - val_acc: 0.7532\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.5806 - acc: 0.8134 - val_loss: 0.7852 - val_acc: 0.7560\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.5735 - acc: 0.8163 - val_loss: 0.8197 - val_acc: 0.7627\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.5803 - acc: 0.8158 - val_loss: 0.8791 - val_acc: 0.7408\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.5576 - acc: 0.8233 - val_loss: 0.9092 - val_acc: 0.7391\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 23s 456us/step - loss: 0.5759 - acc: 0.8191 - val_loss: 0.7806 - val_acc: 0.7633\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 23s 458us/step - loss: 0.5671 - acc: 0.8231 - val_loss: 0.8720 - val_acc: 0.7503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdbb96542e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ykFBvpRmus-z"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.3 Evaluation ᕦ⊙෴⊙ᕤ"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "a6fa2fc7-1e30-4a48-fa03-9f05b9013892",
        "id": "iCUxiYH0us-z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.8720045260429382\n",
            "Test accuracy: 0.7503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NVGI0XRx0mrS"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Our Star Model  with Data Augmentation"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GbDWeuCu0mrY"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.1 Architecture"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VYG83gcD0mrc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o8aPfCXW0mrm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EVomM0JE0mrt"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.2 Training (≖ ‿ ≖)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f4f90a47-35ce-40ab-9901-f80f82a6af61",
        "id": "UAiouAP40mru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        zoom_range=0.1,  # range for random zoom\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        ")\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow()\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size, seed=GENERATOR_SEED),\n",
        "                    epochs=epochs,\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 1.9736 - acc: 0.2567 - val_loss: 1.5962 - val_acc: 0.4149\n",
            "Epoch 2/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 1.6023 - acc: 0.4142 - val_loss: 1.3369 - val_acc: 0.5102\n",
            "Epoch 3/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 1.4174 - acc: 0.4954 - val_loss: 1.1458 - val_acc: 0.5770\n",
            "Epoch 4/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 1.2926 - acc: 0.5479 - val_loss: 1.0401 - val_acc: 0.6277\n",
            "Epoch 5/25\n",
            "1562/1562 [==============================] - 41s 27ms/step - loss: 1.1948 - acc: 0.5871 - val_loss: 0.9687 - val_acc: 0.6620\n",
            "Epoch 6/25\n",
            "1562/1562 [==============================] - 41s 27ms/step - loss: 1.1276 - acc: 0.6128 - val_loss: 0.9314 - val_acc: 0.6765\n",
            "Epoch 7/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 1.0719 - acc: 0.6333 - val_loss: 0.9756 - val_acc: 0.6590\n",
            "Epoch 8/25\n",
            "1562/1562 [==============================] - 42s 27ms/step - loss: 1.0280 - acc: 0.6535 - val_loss: 0.9859 - val_acc: 0.6801\n",
            "Epoch 9/25\n",
            "1562/1562 [==============================] - 42s 27ms/step - loss: 0.9915 - acc: 0.6679 - val_loss: 0.8094 - val_acc: 0.7255\n",
            "Epoch 10/25\n",
            "1562/1562 [==============================] - 42s 27ms/step - loss: 0.9671 - acc: 0.6771 - val_loss: 0.7770 - val_acc: 0.7370\n",
            "Epoch 11/25\n",
            "1562/1562 [==============================] - 42s 27ms/step - loss: 0.9393 - acc: 0.6867 - val_loss: 0.7832 - val_acc: 0.7349\n",
            "Epoch 12/25\n",
            "1562/1562 [==============================] - 42s 27ms/step - loss: 0.9284 - acc: 0.6906 - val_loss: 0.8378 - val_acc: 0.7214\n",
            "Epoch 13/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 0.9033 - acc: 0.7007 - val_loss: 0.8000 - val_acc: 0.7319\n",
            "Epoch 14/25\n",
            "1562/1562 [==============================] - 42s 27ms/step - loss: 0.8951 - acc: 0.7073 - val_loss: 0.7739 - val_acc: 0.7416\n",
            "Epoch 15/25\n",
            "1562/1562 [==============================] - 42s 27ms/step - loss: 0.8785 - acc: 0.7098 - val_loss: 0.7849 - val_acc: 0.7463\n",
            "Epoch 16/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 0.8745 - acc: 0.7125 - val_loss: 0.7458 - val_acc: 0.7486\n",
            "Epoch 17/25\n",
            "1562/1562 [==============================] - 41s 27ms/step - loss: 0.8676 - acc: 0.7169 - val_loss: 0.7750 - val_acc: 0.7458\n",
            "Epoch 18/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 0.8616 - acc: 0.7176 - val_loss: 0.7314 - val_acc: 0.7613\n",
            "Epoch 19/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 0.8487 - acc: 0.7249 - val_loss: 0.7211 - val_acc: 0.7615\n",
            "Epoch 20/25\n",
            "1562/1562 [==============================] - 40s 26ms/step - loss: 0.8357 - acc: 0.7280 - val_loss: 0.7541 - val_acc: 0.7607\n",
            "Epoch 21/25\n",
            "1562/1562 [==============================] - 40s 26ms/step - loss: 0.8380 - acc: 0.7288 - val_loss: 0.7509 - val_acc: 0.7576\n",
            "Epoch 22/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 0.8301 - acc: 0.7312 - val_loss: 0.6985 - val_acc: 0.7689\n",
            "Epoch 23/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 0.8267 - acc: 0.7330 - val_loss: 0.7326 - val_acc: 0.7605\n",
            "Epoch 24/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 0.8243 - acc: 0.7322 - val_loss: 0.7610 - val_acc: 0.7685\n",
            "Epoch 25/25\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 0.8148 - acc: 0.7370 - val_loss: 0.7150 - val_acc: 0.7651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdbb9e28828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-depFtJw0mr2"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.3 Evaluation ᕦ⊙෴⊙ᕤ"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "a27e9147-54d4-4ef6-ef83-c6abb4269d89",
        "id": "nnmM8dWf0mr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.7150107093334198\n",
            "Test accuracy: 0.7651\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}