{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getting_started_with_deep_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumendra/cnn-visualisation/blob/master/notebooks/getting_started_with_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "b-rza-AISL33",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Started with Deep Learning (using Keras)"
      ]
    },
    {
      "metadata": {
        "id": "YpCvHdUzS3rf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST"
      ]
    },
    {
      "metadata": {
        "id": "yQjWtIB6Tdt3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Importing dependencies and setting seeds"
      ]
    },
    {
      "metadata": {
        "id": "EiLJfQ4dW-II",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **Importance of Seed**  \n",
        " Neural Network algorithms make heavy use of randomness, be it for initialization of layer weights or to decide which neurons to dropout.  \n",
        " As a result of this randomness, each training run of a neural network, is bound to produce slightly different results.  \n",
        " This can be a nuisance while experimenting. In order to ensure that our experiments are reproducible (getting the same output every time), by us or anyone else who chooses to run them, we need to seed this randomness.  \n",
        "\n",
        "---\n",
        "**Why are we setting two different seeds?**  \n",
        "Keras relies on `numpy` for some of it's randomness, so we need to seed numpy's random number generator.  \n",
        "Additionally, `Tensorflow` uses it's own random number generator, and since we are using Tensorflow, we need to seed it's random number generator as well.  \n",
        "\n",
        "---\n",
        "More info at -> https://machinelearningmastery.com/reproducible-results-neural-networks-keras/"
      ]
    },
    {
      "metadata": {
        "id": "ykL_rx5vTjXR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FQqFtAaNTjuD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Declaring some constants"
      ]
    },
    {
      "metadata": {
        "id": "pZJ7QMPwa7-f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Epochs**  \n",
        "An `epoch` is said to have completed when our model trains over the entire train dataset `once`.  \n",
        "Hence, number of epochs simply defines the total number of passes our model will make on the entire dataset during training.  \n",
        "\n",
        "---\n",
        "**Batches**  \n",
        "Although the model needs to run over the entire dataset on every epoch, giving the entire dataset as input to the model at once is not feasible. Most of the times our datasets are huge, and using the entire dataset as input will consume a lot of memory.  \n",
        "Hence, we use the concept of batches.  \n",
        "i.e In a single epoch, we make multiple forward and backward passes on the neural network and each time give a subset of entire dataset as input. The size of this subset is called `batch_size`.  \n",
        "This consumes a lot less memory and also helps in training the network faster as we are now updating network weights after every `batch` rather than after every `epoch`.\n"
      ]
    },
    {
      "metadata": {
        "id": "OWO2KI75TuEw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uc-jLIc7T3Fd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Loading and making our dataset usable"
      ]
    },
    {
      "metadata": {
        "id": "3B-Zpf5IjCKn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Why Normalize?**  \n",
        "Normalization in case of image data means dividing it's pixel values by 255.  \n",
        "This brings all pixel values between (0,1).  \n",
        "We've observed that this makes training and convergence much more faster."
      ]
    },
    {
      "metadata": {
        "id": "GMPjfClbT1Em",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q1IY0ixArcxh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_grid(arr):\n",
        "  f, axarr = plt.subplots(2,2)\n",
        "  axarr[0,0].imshow(arr[0])\n",
        "  axarr[0,1].imshow(arr[1])\n",
        "  axarr[1,0].imshow(arr[2])\n",
        "  axarr[1,1].imshow(arr[3])\n",
        "  \n",
        "  axarr[0,0].axis('off')\n",
        "  axarr[0,1].axis('off')\n",
        "  axarr[1,0].axis('off')\n",
        "  axarr[1,1].axis('off')\n",
        "\n",
        "plot_grid(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DK2QQgNvrdGK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train images')\n",
        "print(x_test.shape[0], 'test images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-b0g8hhUM99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. One hot encoding of output classes"
      ]
    },
    {
      "metadata": {
        "id": "c_nRENhyUFw0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to one hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0iQa24QwUmhr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Our first Model üòÅ"
      ]
    },
    {
      "metadata": {
        "id": "fe6FTGajWmH0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.1 Architecture"
      ]
    },
    {
      "metadata": {
        "id": "NvragukgVDMj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cfi_TOwQtCdP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ow6TUh4HWk_7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.2 Training (‚âñ ‚Äø ‚âñ)"
      ]
    },
    {
      "metadata": {
        "id": "6get0qRfWgAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YiPW-s4oWv4_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.3 Evaluation ·ï¶‚äô‡∑¥‚äô·ï§"
      ]
    },
    {
      "metadata": {
        "id": "uELdw91iXQGO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BST6VVyZZQEb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Let's go Deeper! ·ïï( ·êõ )·ïó"
      ]
    },
    {
      "metadata": {
        "id": "XKFsLNu5sl4b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Go Deeper](https://cdn-images-1.medium.com/max/1600/1*RuDCBpDFK4fuBo6W5OFsEw.jpeg)"
      ]
    },
    {
      "metadata": {
        "id": "W1qjlwc2Ztut",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.1 Architecture"
      ]
    },
    {
      "metadata": {
        "id": "wfLIhEPpZi1m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9BGWfXSItHxS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gri5Vw5gZwUA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.2 Training"
      ]
    },
    {
      "metadata": {
        "id": "eUg4ZzbmZyyb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBOz9dbBZ1Jy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.3 Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "WBlOWs9XZ350",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n3oQdWiCbi6-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CIFAR10"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BcEtYgQ5uOz2"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Importing dependencies and setting seeds"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MPYQ7CAJuO0F",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "GENERATOR_SEED = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KXN3pkvyuO0S"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Declaring some constants"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7hvMYs1EuO0U",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "input_shape = (img_rows, img_cols, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tzYhRaNguO0Z"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Loading and making our dataset usable"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6Lp_Gns4uO0b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JOyehUQAuO0d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_grid(arr):\n",
        "  f, axarr = plt.subplots(2,2)\n",
        "  axarr[0,0].imshow(arr[0])\n",
        "  axarr[0,1].imshow(arr[1])\n",
        "  axarr[1,0].imshow(arr[2])\n",
        "  axarr[1,1].imshow(arr[3])\n",
        "  \n",
        "  axarr[0,0].axis('off')\n",
        "  axarr[0,1].axis('off')\n",
        "  axarr[1,0].axis('off')\n",
        "  axarr[1,1].axis('off')\n",
        "\n",
        "plot_grid(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BX6IQrHzuO0h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0dVdwiD_uO0m"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. One hot encoding of output classes"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WrGqT8fAuO0m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to one hot encodings\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ouoCAL6bus-Y"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Our Star Model üòÅ"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Zernbsu-us-a"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.1 Architecture"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C3Z8Z9UNus-c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ElrmRftEus-h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "CLl-VSklus-p"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.2 Training (‚âñ ‚Äø ‚âñ)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tUyut9Rhus-s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ykFBvpRmus-z"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.3 Evaluation ·ï¶‚äô‡∑¥‚äô·ï§"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iCUxiYH0us-z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NVGI0XRx0mrS"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Our Star Model  with Data Augmentation"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GbDWeuCu0mrY"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.1 Architecture"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VYG83gcD0mrc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o8aPfCXW0mrm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EVomM0JE0mrt"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.2 Training (‚âñ ‚Äø ‚âñ)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UAiouAP40mru",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        zoom_range=0.1,  # range for random zoom\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        ")\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow()\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size, seed=GENERATOR_SEED),\n",
        "                    epochs=epochs,\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-depFtJw0mr2"
      },
      "cell_type": "markdown",
      "source": [
        "#### 6.3 Evaluation ·ï¶‚äô‡∑¥‚äô·ï§"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nnmM8dWf0mr3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}